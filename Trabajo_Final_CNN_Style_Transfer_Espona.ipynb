{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo_Final_CNN_Style_Transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quiroo/Trabajo-Final-CV/blob/main/Trabajo_Final_CNN_Style_Transfer_Espona.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCY6UbkkI9_N"
      },
      "source": [
        "# Style Transfer\n",
        "\n",
        "<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n",
        "\n",
        "La idea de este trabajo final es reproducir el siguiente paper:\n",
        "\n",
        "https://arxiv.org/pdf/1508.06576.pdf\n",
        "\n",
        "El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n",
        "\n",
        "Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n",
        "\n",
        "A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n",
        "\n",
        "Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n",
        "\n",
        "La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n",
        "\n",
        "A este procedimiento se lo denomina neural style transfer.\n",
        "\n",
        "# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n",
        "\n",
        "# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n",
        "\n",
        "Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYmSp5-g5v-h",
        "outputId": "589d944a-91e1-47ee-e823-814d8b13fe6a"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyHsa2t0SxZi",
        "outputId": "9c60772b-c666-423a-e7b2-721c390ef941"
      },
      "source": [
        "# Imagen para estilo\n",
        "#!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n",
        "#!wget https://conceptodefinicion.de/wp-content/uploads/2020/12/arte.jpg \n",
        "!wget https://raw.githubusercontent.com/Quiroo/Trabajo-Final-CV/main/arte_style.jpg\n",
        "\n",
        "# Imagen para contenido\n",
        "#!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n",
        "#!wget https://i.ibb.co/tsvJj48/kiro-LA.jpg\n",
        "!wget https://raw.githubusercontent.com/Quiroo/Trabajo-Final-CV/main/kiro_test.jpg\n",
        "\n",
        "# Creamos el directorio para los archivos de salida\n",
        "!mkdir /content/output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-30 18:47:43--  https://raw.githubusercontent.com/Quiroo/Trabajo-Final-CV/main/arte_style.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69725 (68K) [image/jpeg]\n",
            "Saving to: ‘arte_style.jpg’\n",
            "\n",
            "arte_style.jpg      100%[===================>]  68.09K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-09-30 18:47:43 (14.6 MB/s) - ‘arte_style.jpg’ saved [69725/69725]\n",
            "\n",
            "--2021-09-30 18:47:43--  https://raw.githubusercontent.com/Quiroo/Trabajo-Final-CV/main/kiro_test.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 177540 (173K) [image/jpeg]\n",
            "Saving to: ‘kiro_test.jpg’\n",
            "\n",
            "kiro_test.jpg       100%[===================>] 173.38K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-09-30 18:47:43 (16.7 MB/s) - ‘kiro_test.jpg’ saved [177540/177540]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIxH20o2eFoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47971a61-8fa7-4c0b-eb7c-13e0d6d514bf"
      },
      "source": [
        "from keras.preprocessing.image import load_img, save_img, img_to_array\n",
        "import numpy as np\n",
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "import time\n",
        "import argparse\n",
        "\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "from pathlib import Path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajtV4O0Yhis5",
        "outputId": "aaa1ff0a-6964-4a35-9403-b5e3fe0573d2"
      },
      "source": [
        "ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arte_style.jpg  kiro_test.jpg  \u001b[0m\u001b[01;34moutput\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLkV1bnFl_tK"
      },
      "source": [
        "# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n",
        "\n",
        "#base_image_path = Path(\"./775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n",
        "#style_reference_image_path = Path(\"./La_noche_estrellada1.jpg\")\n",
        "\n",
        "#base_image_path = Path(\"./kiro-LA.jpg\")\n",
        "#style_reference_image_path = Path(\"./arte.jpg\")\n",
        "\n",
        "base_image_path = Path(\"./kiro_test.jpg\")\n",
        "style_reference_image_path = Path(\"./arte_style.jpg\")\n",
        "\n",
        "result_prefix = Path(\"./output\")\n",
        "iterations = 100"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2PeGfpeYzj"
      },
      "source": [
        "# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "Los parametros definidos en la siguiente celda hacen referencia a la relación de peso que se le da entre el contenido y el estilo.\n",
        "\n",
        "Siendo α y β los factores de ponderación para la reconstrucción de contenido y estilo, respectivamente.\n",
        "α = content_weight\n",
        "β = style_weight\n",
        "\n",
        "Se relaciona con la Loss de la siguiente manera:\n",
        "Ltotal(p,a, x) = αLcontent(p, x) + βLstyle(a, x) \n",
        "\n",
        "Por último toal_variation_weight es un factor de suavizado de la loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9Dt3aaEmJWS"
      },
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQC0-of_4VZi",
        "outputId": "a2d43aff-da11-464f-bae7-69341e3cc208"
      },
      "source": [
        "ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "arte_style.jpg  kiro_test.jpg  \u001b[0m\u001b[01;34moutput\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQJOhCVuse6"
      },
      "source": [
        "# Neckarfront tiene dimension 775 x 599\n",
        "# Estrallada tiene dimension 745 x 596\n",
        "\n",
        "# Definimos el tamaño de las imágenes a utilizar\n",
        "width, height = load_img(base_image_path).size\n",
        "img_nrows = 400\n",
        "img_ncols = int(width * img_nrows / height)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NSxjVFP4VZk",
        "outputId": "3a32bad3-e74a-4acd-d6a3-124eee2da6dd"
      },
      "source": [
        "print(width)\n",
        "print(height)\n",
        "print(img_nrows)\n",
        "print(img_ncols)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "965\n",
            "723\n",
            "400\n",
            "533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg2ct-8agm1E"
      },
      "source": [
        "# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n",
        "\n",
        "Ayuda: https://keras.io/applications/\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "Carga la imagen con las dimensiones establecidas 400 x 533 (x3 RGB).\n",
        "\n",
        "    img = img_to_array(img)\n",
        "Convierte la imágen en un numpay 3D array.\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "Inserta un nuevo eje que aparecerá en la posición (0) del eje en la forma de matriz expandida. Esto se realiza para hacer coincidir el formato NHWC (número, altura, ancho, canal) de keras.\n",
        "\n",
        "    img = vgg19.preprocess_input(img)\n",
        "Convierte las imágenes de entrada de RGB a BGR, luego centrará en cero cada canal de color con respecto al conjunto de datos de ImageNet, sin escalar. Se definen los pesos de ImageNet al momento de crear el modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAkljg4zuzYd"
      },
      "source": [
        "def preprocess_image(image_path):\n",
        "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg19.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTf0YDSagt10"
      },
      "source": [
        "# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "Con el deprocesamiento de la imagen, se elimina el centro cero a cada capa y reordena nuevamente a RGB. Se utilizará para reconstruir la imagen de salida."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5LaTrsAu14z"
      },
      "source": [
        "def deprocess_image(x):\n",
        "    x = x.reshape((img_nrows, img_ncols, 3))\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYNio09mu4S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ec71ecd-9670-465e-fc70-c35d092c20f8"
      },
      "source": [
        "# get tensor representations of our images\n",
        "# K.variable convierte un numpy array en un tensor, para \n",
        "base_image = K.variable(preprocess_image(base_image_path))\n",
        "style_reference_image = K.variable(preprocess_image(style_reference_image_path))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1Lbw02Uu--o"
      },
      "source": [
        "combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJEi0YI3Uzrm"
      },
      "source": [
        "Aclaración:\n",
        "\n",
        "La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGO_jGFfvEbF"
      },
      "source": [
        "# combine the 3 images into a single Keras tensor\n",
        "input_tensor = K.concatenate([base_image,\n",
        "                              style_reference_image,\n",
        "                              combination_image], axis=0)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdG59VRavHGB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779f32cb-887b-4db4-b1bb-2f1957d0de78"
      },
      "source": [
        "# build the VGG19 network with our 3 images as input\n",
        "# the model will be loaded with pre-trained ImageNet weights\n",
        "model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                    weights='imagenet', include_top=False)\n",
        "print('Model loaded.')\n",
        "\n",
        "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
        "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70-vs_jZkKVc"
      },
      "source": [
        "# 4) En la siguientes celdas:\n",
        "\n",
        "- ¿Qué es la matriz de Gram?¿Para qué se usa?\n",
        "\n",
        "La matriz de Gram de una lista de vectores en un espacio con\n",
        "producto interno, es decir, la matriz resultante de hacer el producto escalar de 2 vectores. \n",
        "\n",
        "En particular de este proyecto se vectorizan los feature maps y se realiza el producto escalar entre ambos. Se utiliza como parte del cálculo de la loss de estilo donde se minimiza la distancia cuadrática entre la matriz de Gram de la imagen original y de la imagen que es generada para mantener la representación del estilo.\n",
        "\n",
        "- ¿Por qué se permutan las dimensiones de x?\n",
        "\n",
        "Se permutan las dimensiones de x para llevar la dimension de canales a la primer dimension, y así, al aplicar el flatten genere 3 tensores, uno para cada canal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1FODPATvJ1k"
      },
      "source": [
        "def gram_matrix(x):\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBQkKFY0Rbx-"
      },
      "source": [
        "# 5) Losses:\n",
        "\n",
        "Explicar qué mide cada una de las losses en las siguientes tres celdas.\n",
        "\n",
        "Rta:\n",
        "\n",
        "La primera (style_loss) calcula la Loss entre el estilo tomando la distancia \n",
        "\n",
        "1.   La primera (style_loss) calcula la Loss entre el estilo tomando la distancia cuadrática entre la matriz de Gram del estilo de las capas de feature y la salida(combinación entre estilo y contenido).\n",
        "\n",
        "    feature_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "2.   La segunda (content_loss) calcula la Loss tomando la distancia cuadrática entre la imagen de contenido y la salida. Evaluando la diferencia entre contenido y la imagen generada.\n",
        "\n",
        "    layer_features = outputs_dict['block5_conv2']\n",
        "\n",
        "3.   La tercera (total_variation_loss) actua sobre la imagen generada, calculando la Loss del cuadrado de la diferencia entre pixels, Para A entre filas y B entre columnas, elevando a un factor 1,25. El objetivo de esta es suavizar la imagen.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Gt0ahWvN6q"
      },
      "source": [
        "def style_loss(style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = img_nrows * img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCqnju5RvQCo"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEp5h31vRnY"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-65vcinbvTZ0"
      },
      "source": [
        "# Armamos la loss total\n",
        "loss = K.variable(0.0)\n",
        "layer_features = outputs_dict['block5_conv2']\n",
        "base_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + content_weight * content_loss(base_image_features,\n",
        "                                            combination_features)\n",
        "\n",
        "feature_layers = ['block1_conv1', 'block2_conv1',\n",
        "                  'block3_conv1', 'block4_conv1',\n",
        "                  'block5_conv1']\n",
        "for layer_name in feature_layers:\n",
        "    layer_features = outputs_dict[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :] \n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features)\n",
        "    loss = loss + (style_weight / len(feature_layers)) * sl\n",
        "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdQWhytFSXC"
      },
      "source": [
        "from tensorflow import GradientTape"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbz4n1OhvV2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d36ec7-bea8-4ef3-9e20-27eee32f4883"
      },
      "source": [
        "grads = K.gradients(loss, combination_image)\n",
        "\n",
        "outputs = [loss]\n",
        "if isinstance(grads, (list, tuple)):\n",
        "    outputs += grads\n",
        "else:\n",
        "    outputs.append(grads)\n",
        "\n",
        "f_outputs = K.function([combination_image], outputs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JbydbOaVcvU"
      },
      "source": [
        "# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "\n",
        "\n",
        "1.   La función eval_loss_and_grads devuelve el valor de los gradientes y de la Loss de la imagen generada\n",
        "2.   La clase Evaluator define las funciones Loss y Grads que luego se va a utilizar en como parámetro para fmin_l_bfgs_b\n",
        "3.   La función fmin_l_bfgs_b se encarga de minizar la loss utilizando los gradientes, ambos definidos en Evaluator. El  l_bfgs_b es un método de optimización Newtoniano realizando una aproximación de la matrix Heseniana utilizando el gradiente. Con este método se obtienen beneficios en tiempos de complejidad computacional.\n",
        "      En el paper se explica como se realiza el calculo dela loss, pero no hay mención sobre el método elegido para minimizar.\n",
        "\n",
        "Diferencias entre la implementación y el Paper:\n",
        "* En el Paper no se menciona el termino de la loss asociado a total_variation. Al agregar este termino se nota una mejoría en la calidad final de la imagen combinada, lo cual se puede apreciar en el punto 8 de este trabajo.\n",
        "\n",
        "* Otra diferencia con el Paper es la utilización de las capas de downsampling. En la implementación se utiliza la VGG19 sin modificar, realizando max-pooling, sin embargo en el paper recomiendan cambiar por average-pooling y asi mejorar el flujo de gradiente y se obteniendo resultados ligeramente más atractivos.\n",
        "\n",
        "* Por último, la capa elegida para la reconstrucción del contenido es el bloque 5 ['block5_conv2'] y no el 4 ['block2_conv2']. Como se indica en el paper, a capas más profundas se la imagen construida tiende a parecerse más al estilo, perdiendo un poco del contenido.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVE1_qemvZeN"
      },
      "source": [
        "def eval_loss_and_grads(x):\n",
        "    x = x.reshape((1, img_nrows, img_ncols, 3))\n",
        "    outs = f_outputs([x])\n",
        "    loss_value = outs[0]\n",
        "    if len(outs[1:]) == 1:\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "    else:\n",
        "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
        "    return loss_value, grad_values\n",
        "\n",
        "# this Evaluator class makes it possible\n",
        "# to compute loss and gradients in one pass\n",
        "# while retrieving them via two separate functions,\n",
        "# \"loss\" and \"grads\". This is done because scipy.optimize\n",
        "# requires separate functions for loss and gradients,\n",
        "# but computing them separately would be inefficient."
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbl9roIgvdb1"
      },
      "source": [
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        loss_value, grad_values = eval_loss_and_grads(x)\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sb0yOEl-WOE6"
      },
      "source": [
        "# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5L6l2s5X-RF"
      },
      "source": [
        "total_variation_weight = 0.1\n",
        "style_weight = 10\n",
        "content_weight = 1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n31YBwCVvhAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6813bafb-d56a-4267-9691-f3896819f4f6"
      },
      "source": [
        "evaluator = Evaluator()\n",
        "\n",
        "# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss\n",
        "x = preprocess_image(base_image_path)\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', i)\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    # save current generated image\n",
        "    img = deprocess_image(x.copy())\n",
        "    fname = result_prefix / ('./8_output_at_iteration_%d.png' % i)\n",
        "    #fname = Path('./output/output_at_iteration_%d.png' % i)\n",
        "    save_img(fname, img)\n",
        "    end_time = time.time()\n",
        "    print('Image saved as', fname)\n",
        "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start of iteration 0\n",
            "Current loss value: 30888962000.0\n",
            "Image saved as output/8_output_at_iteration_0.png\n",
            "Iteration 0 completed in 25s\n",
            "Start of iteration 1\n",
            "Current loss value: 12609400000.0\n",
            "Image saved as output/8_output_at_iteration_1.png\n",
            "Iteration 1 completed in 15s\n",
            "Start of iteration 2\n",
            "Current loss value: 8332129300.0\n",
            "Image saved as output/8_output_at_iteration_2.png\n",
            "Iteration 2 completed in 15s\n",
            "Start of iteration 3\n",
            "Current loss value: 6352002600.0\n",
            "Image saved as output/8_output_at_iteration_3.png\n",
            "Iteration 3 completed in 15s\n",
            "Start of iteration 4\n",
            "Current loss value: 5274270700.0\n",
            "Image saved as output/8_output_at_iteration_4.png\n",
            "Iteration 4 completed in 15s\n",
            "Start of iteration 5\n",
            "Current loss value: 4639779000.0\n",
            "Image saved as output/8_output_at_iteration_5.png\n",
            "Iteration 5 completed in 15s\n",
            "Start of iteration 6\n",
            "Current loss value: 4135718400.0\n",
            "Image saved as output/8_output_at_iteration_6.png\n",
            "Iteration 6 completed in 15s\n",
            "Start of iteration 7\n",
            "Current loss value: 3769302300.0\n",
            "Image saved as output/8_output_at_iteration_7.png\n",
            "Iteration 7 completed in 15s\n",
            "Start of iteration 8\n",
            "Current loss value: 3443440000.0\n",
            "Image saved as output/8_output_at_iteration_8.png\n",
            "Iteration 8 completed in 15s\n",
            "Start of iteration 9\n",
            "Current loss value: 3223930000.0\n",
            "Image saved as output/8_output_at_iteration_9.png\n",
            "Iteration 9 completed in 15s\n",
            "Start of iteration 10\n",
            "Current loss value: 3065542700.0\n",
            "Image saved as output/8_output_at_iteration_10.png\n",
            "Iteration 10 completed in 15s\n",
            "Start of iteration 11\n",
            "Current loss value: 2936175400.0\n",
            "Image saved as output/8_output_at_iteration_11.png\n",
            "Iteration 11 completed in 15s\n",
            "Start of iteration 12\n",
            "Current loss value: 2815779800.0\n",
            "Image saved as output/8_output_at_iteration_12.png\n",
            "Iteration 12 completed in 15s\n",
            "Start of iteration 13\n",
            "Current loss value: 2714847200.0\n",
            "Image saved as output/8_output_at_iteration_13.png\n",
            "Iteration 13 completed in 15s\n",
            "Start of iteration 14\n",
            "Current loss value: 2639561200.0\n",
            "Image saved as output/8_output_at_iteration_14.png\n",
            "Iteration 14 completed in 15s\n",
            "Start of iteration 15\n",
            "Current loss value: 2555338800.0\n",
            "Image saved as output/8_output_at_iteration_15.png\n",
            "Iteration 15 completed in 15s\n",
            "Start of iteration 16\n",
            "Current loss value: 2481179100.0\n",
            "Image saved as output/8_output_at_iteration_16.png\n",
            "Iteration 16 completed in 15s\n",
            "Start of iteration 17\n",
            "Current loss value: 2373598200.0\n",
            "Image saved as output/8_output_at_iteration_17.png\n",
            "Iteration 17 completed in 15s\n",
            "Start of iteration 18\n",
            "Current loss value: 2308941300.0\n",
            "Image saved as output/8_output_at_iteration_18.png\n",
            "Iteration 18 completed in 15s\n",
            "Start of iteration 19\n",
            "Current loss value: 2253879800.0\n",
            "Image saved as output/8_output_at_iteration_19.png\n",
            "Iteration 19 completed in 15s\n",
            "Start of iteration 20\n",
            "Current loss value: 2206045200.0\n",
            "Image saved as output/8_output_at_iteration_20.png\n",
            "Iteration 20 completed in 15s\n",
            "Start of iteration 21\n",
            "Current loss value: 2164890000.0\n",
            "Image saved as output/8_output_at_iteration_21.png\n",
            "Iteration 21 completed in 15s\n",
            "Start of iteration 22\n",
            "Current loss value: 2126911700.0\n",
            "Image saved as output/8_output_at_iteration_22.png\n",
            "Iteration 22 completed in 15s\n",
            "Start of iteration 23\n",
            "Current loss value: 2095186600.0\n",
            "Image saved as output/8_output_at_iteration_23.png\n",
            "Iteration 23 completed in 15s\n",
            "Start of iteration 24\n",
            "Current loss value: 2061124100.0\n",
            "Image saved as output/8_output_at_iteration_24.png\n",
            "Iteration 24 completed in 15s\n",
            "Start of iteration 25\n",
            "Current loss value: 2025678800.0\n",
            "Image saved as output/8_output_at_iteration_25.png\n",
            "Iteration 25 completed in 15s\n",
            "Start of iteration 26\n",
            "Current loss value: 1994478600.0\n",
            "Image saved as output/8_output_at_iteration_26.png\n",
            "Iteration 26 completed in 15s\n",
            "Start of iteration 27\n",
            "Current loss value: 1964538900.0\n",
            "Image saved as output/8_output_at_iteration_27.png\n",
            "Iteration 27 completed in 15s\n",
            "Start of iteration 28\n",
            "Current loss value: 1931793200.0\n",
            "Image saved as output/8_output_at_iteration_28.png\n",
            "Iteration 28 completed in 15s\n",
            "Start of iteration 29\n",
            "Current loss value: 1902923500.0\n",
            "Image saved as output/8_output_at_iteration_29.png\n",
            "Iteration 29 completed in 15s\n",
            "Start of iteration 30\n",
            "Current loss value: 1882053800.0\n",
            "Image saved as output/8_output_at_iteration_30.png\n",
            "Iteration 30 completed in 15s\n",
            "Start of iteration 31\n",
            "Current loss value: 1861797500.0\n",
            "Image saved as output/8_output_at_iteration_31.png\n",
            "Iteration 31 completed in 15s\n",
            "Start of iteration 32\n",
            "Current loss value: 1842269400.0\n",
            "Image saved as output/8_output_at_iteration_32.png\n",
            "Iteration 32 completed in 15s\n",
            "Start of iteration 33\n",
            "Current loss value: 1819444100.0\n",
            "Image saved as output/8_output_at_iteration_33.png\n",
            "Iteration 33 completed in 15s\n",
            "Start of iteration 34\n",
            "Current loss value: 1801467300.0\n",
            "Image saved as output/8_output_at_iteration_34.png\n",
            "Iteration 34 completed in 15s\n",
            "Start of iteration 35\n",
            "Current loss value: 1769607400.0\n",
            "Image saved as output/8_output_at_iteration_35.png\n",
            "Iteration 35 completed in 15s\n",
            "Start of iteration 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn_esJLoqWU5"
      },
      "source": [
        "!zip -r /content/6_file.zip /content/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFmT1oQttB6t"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/6_file.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUBTMa2veEnM"
      },
      "source": [
        "files.download(\"/content/output/8_output_at_iteration_0.png\")\n",
        "files.download(\"/content/output/8_output_at_iteration_99.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkiJtofbWWy1"
      },
      "source": [
        "# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "0. Notebook original:\n",
        "\n",
        " * total_variation_weight: 0,1\n",
        " * β = style_weight: 10\n",
        " * α = content_weight: 1\n",
        " * ratio (α/β): 0,1\n",
        "\n",
        "1. Test_1 \n",
        "\n",
        " * style_weight: 30\n",
        " * content_weight: 1\n",
        " * ratio (α/β): 0,03\n",
        "\n",
        "2. Test_2\n",
        "\n",
        " * style_weight = 1\n",
        " * content_weight = 1\n",
        " * ratio (α/β): 1\n",
        "\n",
        "\n",
        "3. Test_3\n",
        "\n",
        " * style_weight = 1\n",
        " * content_weight = 10\n",
        " * ratio (α/β): 10\n",
        "\n",
        "4. Test_4\n",
        "\n",
        " * style_weight = 1\n",
        " * content_weight = 100\n",
        " * ratio (α/β): 100\n",
        " \n",
        "5. Test_5\n",
        "\n",
        " * style_weight = 1\n",
        " * content_weight = 10000\n",
        " * ratio (α/β): 10000\n",
        "\n",
        "6. Test_6\n",
        "\n",
        " * style_weight = 100\n",
        " * content_weight = 1\n",
        " * ratio (α/β): 0,01\n",
        "\n",
        "7. Test_7\n",
        "\n",
        " * style_weight = 10000 \n",
        " * content_weight = 0,1\n",
        " * ratio (α/β): 0,0001\n",
        "\n",
        "8. Test_8\n",
        "\n",
        " * style_weight = 1000\n",
        " * content_weight = 0.001\n",
        " * ratio (α/β): 10^7\n",
        "\n",
        "9. Test_9 - Total_var\n",
        "\n",
        " * total_variation_weight: 0,1\n",
        " * style_weight = 10\n",
        " * content_weight = 1\n",
        " * ratio (α/β): 0.1\n",
        "\n",
        "10. Test_9 - Total_var\n",
        "\n",
        " * total_variation_weight: 10\n",
        " * style_weight = 10\n",
        " * content_weight = 1\n",
        " * ratio (α/β): 0.1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7Qvoh_HYaHM"
      },
      "source": [
        "# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n",
        "\n",
        "Respuesta:\n",
        "\n",
        "https://conceptodefinicion.de/wp-content/uploads/2020/12/arte.jpg\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Maa86QYd9o9a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}